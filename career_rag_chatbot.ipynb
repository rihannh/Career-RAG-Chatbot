{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rihannh/Career-RAG-Chatbot/blob/main/career_rag_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Career RAG Chatbot\n",
        "\n",
        "Sistem RAG (Retrieval-Augmented Generation) untuk analisis lowongan kerja menggunakan Groq LLM dan FAISS vector store.\n",
        "\n",
        "## Instalasi Dependencies"
      ],
      "metadata": {
        "id": "QMqHKeEXMHYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUGrrHHeLUMB",
        "outputId": "87bc8f11-417c-40ac-a461-1a93de8b5ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.34.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (0.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq langchain langchain-community langchain-huggingface faiss-cpu tiktoken python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries"
      ],
      "metadata": {
        "id": "bPNU7GXuMLKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPC9C8j9LUMF",
        "outputId": "fc5bdbe4-f431-41b5-aa8d-aeade3b92f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# LangChain core\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Embeddings (updated import)\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# LLM clients\n",
        "from groq import Groq\n",
        "\n",
        "# Utils\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Google Colab specific (comment out if not using Colab)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    IS_COLAB = True\n",
        "except ImportError:\n",
        "    IS_COLAB = False\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Konfigurasi API"
      ],
      "metadata": {
        "id": "pEpDsF7LMOyy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mil6KXtLUMJ",
        "outputId": "de1b0ddf-3017-4b0a-b1d4-bf8b13f221ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Groq client initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Setup Groq API Key\n",
        "if IS_COLAB:\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "else:\n",
        "    # For local development, use environment variable or .env file\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "    if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "        raise ValueError(\"GROQ_API_KEY not found. Please set it in your environment or .env file\")\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "print(\"✓ Groq client initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Loading & Cleaning\n",
        "\n",
        "Memuat dan membersihkan data lowongan kerja dari CSV."
      ],
      "metadata": {
        "id": "NnZcYNG-MRp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JgXmPl7LUMN",
        "outputId": "98fae396-597f-4d5e-d025-1793ffd38ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Data loaded: 742 job postings\n",
            "✓ Columns: ['Job Title', 'Salary Estimate', 'Job Description', 'Rating', 'Company Name', 'Location', 'Headquarters', 'Size', 'Founded', 'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors', 'hourly', 'employer_provided', 'min_salary', 'max_salary', 'avg_salary', 'company_txt', 'job_state', 'same_state', 'age', 'python_yn', 'R_yn', 'spark', 'aws', 'excel', 'job_simp', 'seniority', 'desc_len', 'num_comp']\n"
          ]
        }
      ],
      "source": [
        "def clean_company_name(name):\n",
        "    \"\"\"\n",
        "    Membersihkan nama perusahaan dari rating yang tertempel di akhir.\n",
        "\n",
        "    Args:\n",
        "        name (str): Nama perusahaan yang mungkin mengandung rating (e.g., \"Company 3.8\")\n",
        "\n",
        "    Returns:\n",
        "        str: Nama perusahaan yang sudah dibersihkan\n",
        "    \"\"\"\n",
        "    return re.sub(r\"\\s\\d\\.\\d$\", \"\", str(name))\n",
        "\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"eda_data.csv\")\n",
        "\n",
        "# Remove unnamed column if exists\n",
        "if \"Unnamed: 0\" in df.columns:\n",
        "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "# Clean company names\n",
        "df[\"Company Name\"] = df[\"Company Name\"].apply(clean_company_name)\n",
        "\n",
        "print(f\"✓ Data loaded: {len(df)} job postings\")\n",
        "print(f\"✓ Columns: {list(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Document Processing\n",
        "\n",
        "Membangun dokumen terstruktur dari setiap lowongan kerja dan melakukan text cleaning."
      ],
      "metadata": {
        "id": "6qK2tCCxMUL3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYcfNSXoLUMQ",
        "outputId": "7ae663ea-8992-4f55-eb55-8076d107ea53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Documents created: 742\n"
          ]
        }
      ],
      "source": [
        "def build_document(row):\n",
        "    \"\"\"\n",
        "    Membangun dokumen terstruktur dari baris DataFrame.\n",
        "\n",
        "    Args:\n",
        "        row (pd.Series): Baris DataFrame yang berisi informasi lowongan kerja\n",
        "\n",
        "    Returns:\n",
        "        str: Dokumen terstruktur dalam format teks\n",
        "    \"\"\"\n",
        "    doc = f\"\"\"\n",
        "Job Title: {row['Job Title']}\n",
        "Company: {row['Company Name']}\n",
        "Location: {row['Location']}\n",
        "Salary Estimate: {row['Salary Estimate']}\n",
        "Industry: {row['Industry']}\n",
        "Sector: {row['Sector']}\n",
        "Founded: {row['Founded']}\n",
        "Rating: {row['Rating']}\n",
        "\n",
        "Skills:\n",
        "- Python: {row['python_yn']}\n",
        "- R: {row['R_yn']}\n",
        "- Excel: {row['excel']}\n",
        "- AWS: {row['aws']}\n",
        "- Spark: {row['spark']}\n",
        "\n",
        "Job Description:\n",
        "{row['Job Description']}\n",
        "\"\"\"\n",
        "    return doc\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Membersihkan teks dari multiple newlines dan spasi berlebih.\n",
        "\n",
        "    Args:\n",
        "        text (str): Teks yang akan dibersihkan\n",
        "\n",
        "    Returns:\n",
        "        str: Teks yang sudah dibersihkan\n",
        "    \"\"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r\"\\n+\", \"\\n\", text)  # Hapus multiple newline\n",
        "    text = re.sub(r\"\\s+\", \" \", text)    # Hapus spasi berlebih\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# Build documents\n",
        "df[\"document\"] = df.apply(build_document, axis=1)\n",
        "df[\"document_clean\"] = df[\"document\"].apply(clean_text)\n",
        "\n",
        "print(f\"✓ Documents created: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Text Chunking\n",
        "\n",
        "Membagi dokumen menjadi chunks yang lebih kecil untuk memudahkan retrieval."
      ],
      "metadata": {
        "id": "VK-ga_mUMW1g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcCiE5MwLUOu",
        "outputId": "b52fe4bf-0b04-4522-a49d-44a5c892a4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Total chunks created: 9045\n",
            "✓ Sample chunk length: 265 characters\n"
          ]
        }
      ],
      "source": [
        "# Initialize text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "# Create documents with metadata\n",
        "documents = []\n",
        "for idx, row in df.iterrows():\n",
        "    doc_text = build_document(row)\n",
        "    chunks = text_splitter.split_text(doc_text)\n",
        "\n",
        "    for ch in chunks:\n",
        "        documents.append({\n",
        "            \"text\": ch,\n",
        "            \"metadata\": {\n",
        "                \"job_id\": int(idx),\n",
        "                \"job_title\": str(row[\"Job Title\"]),\n",
        "                \"company\": str(row[\"Company Name\"])\n",
        "            }\n",
        "        })\n",
        "\n",
        "print(f\"✓ Total chunks created: {len(documents)}\")\n",
        "print(f\"✓ Sample chunk length: {len(documents[0]['text'])} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Vector Store Creation\n",
        "\n",
        "Membuat vector store menggunakan FAISS dengan embeddings dari HuggingFace."
      ],
      "metadata": {
        "id": "pyTMIfInMZbC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgfpur5SLUOv",
        "outputId": "d97916f9-6e5f-47f5-cd25-d355299a5fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Embedding model loaded!\n",
            "✓ FAISS vectorstore created with metadata!\n",
            "✓ Vectorstore saved to: career_faiss_index\n"
          ]
        }
      ],
      "source": [
        "# Load embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "print(\"✓ Embedding model loaded!\")\n",
        "\n",
        "# Convert to LangChain Document objects\n",
        "langchain_documents = []\n",
        "for doc_dict in documents:\n",
        "    langchain_documents.append(\n",
        "        Document(\n",
        "            page_content=doc_dict['text'],\n",
        "            metadata=doc_dict['metadata']\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Create vector store\n",
        "vectorstore = FAISS.from_documents(langchain_documents, embedding_model)\n",
        "print(\"✓ FAISS vectorstore created with metadata!\")\n",
        "\n",
        "# Save vector store\n",
        "VECTORSTORE_PATH = \"career_faiss_index\"\n",
        "vectorstore.save_local(VECTORSTORE_PATH)\n",
        "print(f\"✓ Vectorstore saved to: {VECTORSTORE_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. RAG Functions\n",
        "\n",
        "Fungsi-fungsi untuk retrieval dan generation menggunakan RAG pipeline."
      ],
      "metadata": {
        "id": "kSHVPzE8McJy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-Qi-HF1LUOw"
      },
      "outputs": [],
      "source": [
        "def retrieve_docs(query, k=4):\n",
        "    \"\"\"\n",
        "    Melakukan retrieval dokumen yang relevan dengan query.\n",
        "\n",
        "    Args:\n",
        "        query (str): Query dari user\n",
        "        k (int): Jumlah dokumen yang akan di-retrieve (default: 4)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (context_string, metadata_list) - Context yang digabung dan list metadata\n",
        "    \"\"\"\n",
        "    results = vectorstore.similarity_search(query, k=k)\n",
        "    contexts = []\n",
        "    metadata_list = []\n",
        "\n",
        "    for doc in results:\n",
        "        contexts.append(doc.page_content)\n",
        "        metadata_list.append(doc.metadata)\n",
        "\n",
        "    return \"\\n\\n\".join(contexts), metadata_list\n",
        "\n",
        "\n",
        "def build_prompt(user_query, retrieved_context, metadata_list):\n",
        "    # format metadata untuk prompt\n",
        "    metadata_text = \"\\n\".join([\n",
        "        f\"- Job ID {m['job_id']}, Title: {m['job_title']}, Company: {m['company']}\"\n",
        "        for m in metadata_list\n",
        "    ])\n",
        "\n",
        "    return f\"\"\"\n",
        "You are CareerMate, an AI job analysis assistant.\n",
        "\n",
        "You MUST follow these rules:\n",
        "1. Use information from BOTH the context and the metadata.\n",
        "2. If the answer is not available, say:\n",
        "   \"The information is not available in the job postings.\"\n",
        "3. Do NOT add assumptions.\n",
        "4. If two or more jobs are retrieved for the query,\n",
        "   you MUST respond: \"Multiple job postings were retrieved. Please specify which job.\"\n",
        "\n",
        "\n",
        "-----------------------\n",
        "RETRIEVED CONTEXT:\n",
        "{retrieved_context}\n",
        "\n",
        "-----------------------\n",
        "RETRIEVED METADATA:\n",
        "{metadata_text}\n",
        "\n",
        "-----------------------\n",
        "USER QUESTION:\n",
        "{user_query}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def rag_answer(query, model=\"llama-3.1-8b-instant\", k=4):\n",
        "\n",
        "    context, metadata_list = retrieve_docs(query, k=k)\n",
        "\n",
        "    prompt = build_prompt(query, context, metadata_list)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are CareerMate, an expert job insights assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    return answer, metadata_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Usage Examples\n",
        "\n",
        "Contoh penggunaan sistem RAG untuk menjawab pertanyaan tentang lowongan kerja.\n"
      ],
      "metadata": {
        "id": "kGqpow8EMetf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Case 1 — Skill Extraction\n",
        "query_1 = \"What skills are required for a Data Scientist?\"\n",
        "\n",
        "# Use Case 2 — Job Requirements / Qualifications\n",
        "query_2 = \"Do any jobs require a Master’s degree?\"\n",
        "\n",
        "# Use Case 3 — Responsibilities Extraction\n",
        "query_3 = \"What responsibilities does a Data Scientist have?\"\n",
        "\n",
        "# Use Case 4 — Company Information\n",
        "query_4 = \"Which company is offering a Data Scientist position?\"\n",
        "\n",
        "# Use Case 5 — Location & Salary\n",
        "query_5 = \"What is the salary range for this job?\"\n",
        "\n",
        "# Use Case 6 — Filtering / Matching\n",
        "query_6 = \"Find jobs that require Python but not AWS.\"\n",
        "\n",
        "# Use Case 7 — Comparison\n",
        "query_7 = \"Compare the skills required for Data Scientist and Data Analyst roles.\"\n",
        "\n",
        "# Use Case 8 — Natural Language / Human-friendly Query\n",
        "query_8 = \"Is this a beginner-friendly job?\"\n",
        "\n",
        "# Use Case 9 — Out-of-Scope / Halusinasi Test\n",
        "query_9 = \"Who is the CEO of the company?\"\n"
      ],
      "metadata": {
        "id": "qbi770hMPpMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5dgNx0fLUOy",
        "outputId": "3e87ef1b-9306-4794-b504-f41526f34fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: What skills are required for a Data Scientist?\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " The Data Scientist position requires the following skills based on the provided information:\n",
            "\n",
            "1. Computer programming\n",
            "2. Databases\n",
            "3. Data visualization\n",
            "4. Version control\n",
            "5. Problem-solving skills\n",
            "6. Understanding of clinical relevance\n",
            "\n",
            "These skills are mentioned in the experience requirement section of the job posting.\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 56, Title: Data Scientist, Company: Netskope\n",
            "  2. Job ID: 448, Title: Data Scientist, Company: Netskope\n",
            "  3. Job ID: 451, Title: Data Scientist, Company: CareDx\n",
            "  4. Job ID: 486, Title: Data Scientist, Company: Brillient\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "answer, sources = rag_answer(query_1)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_1)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_2)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_2)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBGje-7TU1L8",
        "outputId": "ebe35ff9-5605-45aa-f6b8-bfc62f08776d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: Do any jobs require a Master’s degree?\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " Yes, the jobs retrieved for this query have several positions that require a Master's degree. \n",
            "\n",
            "Job ID 64 (Data Scientist), Job ID 625 (Data Scientist), Job ID 461 (Data Scientist) all require a Master's degree, preferably in Statistics, Computer Science, Operations Research, Engineering, Mathematics, Economics, or other quantitative fields. Additionally, a Master’s degree in business administration (MBA) or a related field is also required for Job ID 295 (Program/Data Analyst).\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 64, Title: Data Scientist, Company: DICK'S Sporting Goods - Corporate\n",
            "  2. Job ID: 625, Title: Data Scientist, Company: DICK'S Sporting Goods - Corporate\n",
            "  3. Job ID: 461, Title: Data Scientist, Company: PeoplesBank\n",
            "  4. Job ID: 295, Title: Program/Data Analyst, Company: General Dynamics Information Technology\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_3)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_3)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OehaZrkrU1I8",
        "outputId": "617df71b-84b3-46bd-e029-8250801f28b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: What responsibilities does a Data Scientist have?\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " The information is not available in the job postings. However, based on the provided metadata, we can infer some general job descriptions.\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 182, Title: VP, Data Science, Company: PennyMac\n",
            "  2. Job ID: 284, Title: VP, Data Science, Company: PennyMac\n",
            "  3. Job ID: 56, Title: Data Scientist, Company: Netskope\n",
            "  4. Job ID: 448, Title: Data Scientist, Company: Netskope\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_4)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_4)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC1fD7goU1Gf",
        "outputId": "17dd4a5c-0f57-4124-f92e-1750652d6afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: Which company is offering a Data Scientist position?\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " Based on the metadata provided, multiple companies are offering Data Scientist positions. \n",
            "\n",
            "The companies with Data Scientist positions available are:\n",
            "1. TRANZACT (Job ID 656)\n",
            "2. Netskope (Job ID 56 and 448)\n",
            "3. CareDx (Job ID 451)\n",
            "\n",
            "To provide a more accurate answer, please specify which job you are interested in.\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 656, Title: Data Scientist, Company: TRANZACT\n",
            "  2. Job ID: 56, Title: Data Scientist, Company: Netskope\n",
            "  3. Job ID: 448, Title: Data Scientist, Company: Netskope\n",
            "  4. Job ID: 451, Title: Data Scientist, Company: CareDx\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_5)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_5)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVEdjqsMU1An",
        "outputId": "d28d36fb-13e0-4389-b194-a578730fdbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: What is the salary range for this job?\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " Based on the retrieved metadata, I do not see the job description for any job ID. However, I can suggest potential job IDs to retrieve job descriptions and salaries for.\n",
            "\n",
            "To get the salary range for the specified job, you will need to provide more information. Can you please provide the job title and ID?\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 15, Title: Data Engineer I, Company: Audible\n",
            "  2. Job ID: 67, Title: Data Scientist - Research, Company: C Space\n",
            "  3. Job ID: 396, Title: Product Engineer – Spatial Data Science and Statistical Analysis, Company: Esri\n",
            "  4. Job ID: 601, Title: Product Engineer – Spatial Data Science and Statistical Analysis, Company: Esri\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_6)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_6)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOmyNqycU06V",
        "outputId": "65aa6aa1-e58f-42de-84ac-46ca0fb2b57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: Find jobs that require Python but not AWS.\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " Based on the provided context and metadata, I was able to identify potential jobs. However, since none of the job postings directly mention the exclusion of AWS while requiring Python, these jobs do not specifically match your requirements.\n",
            "\n",
            "Multiple job postings (Sr. Data Engineer | Big Data SaaS Pipeline, Data Scientist, Data Engineer, Data Scientist) retrieved, but the job postings don't specify the exclusion of AWS. The metadata only provides information about the required skills for the jobs.\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 649, Title: Sr. Data Engineer | Big Data SaaS Pipeline, Company: Bridg\n",
            "  2. Job ID: 435, Title: Data Scientist, Company: HG Insights\n",
            "  3. Job ID: 267, Title: Data Engineer, Company: PennyMac\n",
            "  4. Job ID: 433, Title: Data Scientist, Company: Change Healthcare\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_7)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_7)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOz8I7qwU02T",
        "outputId": "1074d3a6-0e6f-4204-fba8-1280f0328510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: Compare the skills required for Data Scientist and Data Analyst roles.\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " Based on the provided context and metadata, I've identified the main skill sets required for the Data Scientist and Data Analyst roles:\n",
            "\n",
            "**Data Scientist:**\n",
            "\n",
            "- Bachelor’s degree from an accredited university or college in Data Analytics or Computer Science\n",
            "- 2+ years’ work experience as a data analyst or a related field\n",
            "- Ability to work with stakeholders to assess data output\n",
            "- Ability to translate business requirements into non-technical, lay terms\n",
            "- Proactive, self-motivated, able to recognize issues and resolve or escalate appropriately\n",
            "- Excellent interpersonal skills, both in person and over the phone\n",
            "- Previous experience working with statistical and/or predictive model development\n",
            "- Experience with large-scale implementations of statistical methods to build decision support or recommender systems\n",
            "- Innovative and entrepreneurial mindset\n",
            "- Ability to work independently and oversee mid-level analysts\n",
            "- Demonstrated track record of solving quantitative problems\n",
            "\n",
            "**Data Analyst:**\n",
            "\n",
            "- Bachelor’s degree from an accredited university or college in Data Analytics or Computer Science\n",
            "- Ability to provide imaginative, thorough, practicable, and consistent solutions with organizational objectives\n",
            "- Present findings to both technical and non-technical collaborators and stakeholders\n",
            "- Gather and analyze data across sources and systems to identify trends and derive recommendations or make predictions\n",
            "- Supervise, mentor, guide other data analysts\n",
            "- Experience in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle, and Data Management (for senior-level Data Analyst)\n",
            "\n",
            "Comparing the skills, here are the key differences:\n",
            "\n",
            "1. **Technical Expertise:** Data Scientists require more advanced technical skills, including experience with statistical and predictive model development, large-scale implementations, and a track record of solving quantitative problems. Data Analysts, on the other hand, focus more on data analysis, interpretation, and presentation.\n",
            "2. **Leadership and Supervision:** Data Analysts are expected to supervise and mentor junior analysts, while Data Scientists focus more on individual problem-solving and innovative thinking.\n",
            "3. **Scope and Complexity:** Data Scientists tackle more complex and strategic problems, often requiring innovative and entrepreneurial solutions. Data Analysts focus on more routine data analysis and reporting tasks.\n",
            "\n",
            "In summary, while both roles require strong analytical and problem-solving skills, Data Scientists have a greater emphasis on technical expertise, innovation, and leadership, while Data Analysts focus on more general data analysis and reporting tasks.\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 85, Title: Data Analyst, Company: Gensco\n",
            "  2. Job ID: 674, Title: Data Scientist, Company: CompQsoft\n",
            "  3. Job ID: 567, Title: Senior Data Analyst, Company: Novetta\n",
            "  4. Job ID: 462, Title: Data Scientist Manager, Company: Capgemini\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_8)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_8)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYmn_QLU0rZ",
        "outputId": "4a492b2d-e2c9-4091-9f41-60273143b2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: Is this a beginner-friendly job?\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " Multiple job postings were retrieved. Please specify which job.\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 215, Title: Data Scientist, Company: Spectrum Communications and Consulting\n",
            "  2. Job ID: 20, Title: Data Scientist, Company: Porch\n",
            "  3. Job ID: 76, Title: Customer Data Scientist/Sales Engineer (Bay, Company: h2o.ai\n",
            "  4. Job ID: 146, Title: Customer Data Scientist/Sales Engineer, Company: h2o.ai\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer, sources = rag_answer(query_9)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"QUERY:\", query_9)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nANSWER:\\n\", answer)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SOURCES:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"  {i}. Job ID: {source.get('job_id')}, Title: {source.get('job_title')}, Company: {source.get('company')}\")\n",
        "print(\"=\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6ud5I6tU0aA",
        "outputId": "7c1a76a3-e3ef-464f-aac5-df1393647980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "QUERY: Who is the CEO of the company?\n",
            "================================================================================\n",
            "\n",
            "ANSWER:\n",
            " The information is not available in the job postings.\n",
            "\n",
            "================================================================================\n",
            "SOURCES:\n",
            "  1. Job ID: 502, Title: Data Scientist, Company: Strategic Financial Solutions\n",
            "  2. Job ID: 678, Title: Data Scientist, Company: Strategic Financial Solutions\n",
            "  3. Job ID: 175, Title: Senior Data Scientist, Company: Plymouth Rock Assurance\n",
            "  4. Job ID: 268, Title: Senior Data Scientist, Company: Plymouth Rock Assurance\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Loading Saved Vector Store\n",
        "\n",
        "Jika vector store sudah disimpan, dapat dimuat ulang tanpa perlu rebuild."
      ],
      "metadata": {
        "id": "0L_3Hi8wMhan"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE7lVH_8LUO0"
      },
      "outputs": [],
      "source": [
        "# Load saved vector store (uncomment if needed)\n",
        "# vectorstore = FAISS.load_local(\n",
        "#     VECTORSTORE_PATH,\n",
        "#     embedding_model,\n",
        "#     allow_dangerous_deserialization=True\n",
        "# )\n",
        "# print(\"✓ Vectorstore loaded from disk!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXG76frN2wy1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}